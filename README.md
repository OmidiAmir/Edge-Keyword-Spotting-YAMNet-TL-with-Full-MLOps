# Keyword Spotting (Speech Commands) â€” MLOps-Ready Project

Fast, lightweight keyword spotting on the **Google Speech Commands** dataset (subset of 10 common words).  
Trains quickly (<20 min on RTX 3060) and demonstrates a full **MLOps workflow** step by step:  
data â†’ model â†’ tests â†’ config â†’ MLflow tracking â†’ CI/CD â†’ FastAPI API.

---

## ðŸš€ Features so far
- **Dataset** wrapper (`KSDataset`) with MFCC features + class filtering.
- **Training** script with YAML config support.
- **Pytest** smoke tests for dataset + training pipeline.
- **Experiment tracking** with MLflow (logs metrics, artifacts, models).
- **Model export** to TorchScript (`models/ts_model.pt`).
- **FastAPI** inference service (real-time keyword spotting API).

---

## ðŸ“‚ Repo Layout (current)

```bash

keyword-spotting-mlops/
â”œâ”€ pyproject.toml
â”œâ”€ .gitignore
â”œâ”€ README.md
â”œâ”€ data/                   # dataset files (gitignored)
â”‚   â””â”€ SpeechCommands
â”‚       â””â”€ speech_commands_v0.02
â”‚            â””â”€ ...
â”œâ”€ models/                 # exported TorchScript models
â”œâ”€ scripts/                # CLI entry points
â”‚    â”œâ”€ download_data.py   # downloads Speech Commands
â”‚    â”œâ”€ train_model.py     # training with MLflow
â”‚    â”œâ”€ evaluate_model.py  # evaluation for specific run
â”‚    â”œâ”€ export_model.py    # export TorchScript model
â”‚    â””â”€ infer_wav.py       # inference on single WAV file
â”œâ”€ src/
â”‚   â”œâ”€ kws/
â”‚   â”‚   â”œâ”€ __init__.py
â”‚   â”‚   â”œâ”€ data/           # dataset utils
â”‚   â”‚   â”‚  â””â”€ dataset.py
â”‚   â”‚   â”œâ”€ models/         # CNN model
â”‚   â”‚   â””â”€ training/       # training loop
â”œâ”€ tests/                  # pytest unit + smoke tests
â”‚   â””â”€ test_data.py
â””â”€ .github/workflows/
    â””â”€ ci.yml              # GitHub Actions workflow

```

---
## ðŸ›  Requirements
- Python 3.9+
- Torch, Torchaudio, NumPy, tqdm, MLflow, FastAPI, Uvicorn
- (Exact versions pinned in pyproject.toml)
---

## ðŸ›  Installation
```bash
python -m venv .venv
# Activate venv
.venv\Scripts\activate   # Windows
source .venv/bin/activate # macOS/Linux

pip install -e .
```
---

## ðŸ“‚ Dataset
- **Source:** [Google Speech Commands](https://arxiv.org/abs/1804.03209) (v0.02)  
- **Selected classes:** yes, no, up, down, left, right, on, off, stop, go

- Sampling rate: **16 kHz**  
- Format: WAV, 1-second duration

---

## ðŸ§  Baseline Model

- Features: MFCC (n_mfcc=40) + standardization
- Architecture: 3 convolutional blocks â†’ Global Average Pool â†’ Fully Connected
- Parameters: ~0.5M
- Training time: < 20 minutes on RTX 3060

--- 

## ðŸ§ª Training
Run training (logs to MLflow automatically):
```bash
python scripts/train_model.py --data_root data --epochs 10 --batch_size 128

```

---

## ðŸ”„ CI/CD with GitHub Actions

This repo includes a GitHub Actions workflow (.github/workflows/ci.yml) that runs automatically on every push or pull request:
- âœ… Unit tests (dataset + preprocessing)
- âœ… Smoke tests (training & inference run)

This ensures code stays stable and reproducible as new MLOps components are added.

--- 
## ðŸ“ˆ MLflow Tracking
```bash
mlflow ui
```
Then open http://127.0.0.1:5000 to compare experiments and download checkpoints.

---

## ðŸ“¦ Export TorchScript Model
Pick a run from MLflow, export it:
```bash
Pick a run from MLflow, export it:
```
---

```bash
python scripts/infer_wav.py --wav data/SpeechCommands/speech_commands_v0.02/yes/0a7c2a8d_nohash_0.wav

```

## ðŸŒ Serving with FastAPI

Once youâ€™ve exported a TorchScript model to `models/ts_model.pt`, you can serve it via FastAPI.

### Run locally (no Docker)
```bash
uvicorn kws.serve.app:app --host 0.0.0.0 --port 8000 --reload

```
Endpoints:
- GET /health â†’ service status
- GET /selftest â†’ sanity check (generates + reads back a dummy tone)
- POST /predict â†’ keyword prediction for uploaded .wav file
- POST /predict-bytes â†’ keyword prediction from raw audio bytes

Example request:
```bash
# Linux/macOS
curl -F "file=@data/SpeechCommands/speech_commands_v0.02/yes/0a7c2a8d_nohash_0.wav" http://localhost:8000/predict

# Windows PowerShell (using curl.exe instead of alias)
$f="C:\Users\omidi\OneDrive\MyMLProjects\edge-keyword-spotting\data\SpeechCommands\speech_commands_v0.02\yes\0a7c2a8d_nohash_0.wav"
curl.exe -F "file=@$f" http://localhost:8000/predict

```


---

## ðŸ”„ CI/CD with GitHub Actions
This repo includes a GitHub Actions workflow (`.github/workflows/ci.yml`) that runs:
- Unit tests on every push and pull request
- Smoke tests to validate training and inference scripts

This ensures the codebase remains stable as new MLOps components are added.

---
## ðŸ“ˆ Experiment Tracking
- Integrated with MLflow
- Tracks hyperparameters, metrics, and models
- Run selection based on best validation accuracy

---

## ## ðŸš€ Run with Docker

You can run the FastAPI inference service in a container.

### Build the image
```bash
docker build -t kws-api .
``` 
Run the container
```bash
docker run --rm -p 8000:8000 kws-api
```

The API will be available at:
- Health check â†’ http://localhost:8000/health
- Selftest â†’ http://localhost:8000/selftest
- Interactive docs â†’ http://localhost:8000/docs
Example request:
```bash
curl -F "file=@data/SpeechCommands/speech_commands_v0.02/yes/0a7c2a8d_nohash_0.wav" http://localhost:8000/predict

```